{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "x2bRbpq2tq5q"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cVwmHVOoCl0C"
      },
      "source": [
        "Connect to Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oZz6oaZCCnLg",
        "outputId": "a50e2bc6-3164-48e2-cfbc-254d7d1aafeb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content\n",
            "/content/drive/MyDrive/CS439\n"
          ]
        }
      ],
      "source": [
        "drive.mount('/content/drive')\n",
        "# navigate to current directory\n",
        "!pwd\n",
        "%cd drive/MyDrive/CS439/\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ny2X86HWxhnM"
      },
      "source": [
        "Load the training and test data here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Xvq71Hf1vz_0"
      },
      "outputs": [],
      "source": [
        "\n",
        "class BLEDataset(Dataset):\n",
        "    def __init__(self, input_data):\n",
        "        # (x rows, 61 columns)\n",
        "        self.features = input_data[:, :61]\n",
        "        self.labels = F.one_hot(input_data[:, 61].long(), 25).float()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.features[idx], self.labels[idx]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XIVTNYqaxk33"
      },
      "source": [
        "Implement your neural network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Q0LrS9vZxmpl"
      },
      "outputs": [],
      "source": [
        "class LOC_NN(nn.Module):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super(LOC_NN, self).__init__()\n",
        "        \n",
        "        # self.rnn_s = list()\n",
        "        # for i in range(12):\n",
        "        #     self.rnn_s.append(nn.RNN(1, 5, batch_first=True).to(device))\n",
        "\n",
        "        self.ll_s = []\n",
        "        for i in range(12):\n",
        "            self.ll_s.append(nn.Linear(5, 5).to(device))\n",
        "\n",
        "\n",
        "        self.orien_em = nn.Embedding(4,10).to(device)\n",
        "        self.hidden_layer = nn.Linear(70, 25).to(device)\n",
        "        self.output_layer = nn.Linear(25, 25).to(device)\n",
        "\n",
        "    def forward(self, x): # x:(batch_size, 61)\n",
        "        batch_size, _ = x.shape\n",
        "        rnn_vals_flatten = x[:, :60]\n",
        "        rnn_vals_mat = torch.reshape(rnn_vals_flatten, (batch_size, 12, 5))\n",
        "        orient = x[:,60]\n",
        "        # # RNN input tensor (5,1), output (1, 5)\n",
        "        # h_n0 = self.rnn_s[0](torch.reshape(rnn_vals_mat[:,0], (batch_size, 5, 1)).float())[1].squeeze(0)\n",
        "        # h_n1 = self.rnn_s[1](torch.reshape(rnn_vals_mat[:,1], (batch_size, 5, 1)).float())[1].squeeze(0)\n",
        "        # h_n2 = self.rnn_s[2](torch.reshape(rnn_vals_mat[:,2], (batch_size, 5, 1)).float())[1].squeeze(0)\n",
        "        # h_n3 = self.rnn_s[3](torch.reshape(rnn_vals_mat[:,3], (batch_size, 5, 1)).float())[1].squeeze(0)\n",
        "        # h_n4 = self.rnn_s[4](torch.reshape(rnn_vals_mat[:,4], (batch_size, 5, 1)).float())[1].squeeze(0)\n",
        "        # h_n5 = self.rnn_s[5](torch.reshape(rnn_vals_mat[:,5], (batch_size, 5, 1)).float())[1].squeeze(0)\n",
        "        # h_n6 = self.rnn_s[6](torch.reshape(rnn_vals_mat[:,6], (batch_size, 5, 1)).float())[1].squeeze(0)\n",
        "        # h_n7 = self.rnn_s[7](torch.reshape(rnn_vals_mat[:,7], (batch_size, 5, 1)).float())[1].squeeze(0)\n",
        "        # h_n8 = self.rnn_s[8](torch.reshape(rnn_vals_mat[:,8], (batch_size, 5, 1)).float())[1].squeeze(0)\n",
        "        # h_n9 = self.rnn_s[9](torch.reshape(rnn_vals_mat[:,9], (batch_size, 5, 1)).float())[1].squeeze(0)\n",
        "        # h_n10 = self.rnn_s[10](torch.reshape(rnn_vals_mat[:,10], (batch_size, 5, 1)).float())[1].squeeze(0)\n",
        "        # h_n11 = self.rnn_s[11](torch.reshape(rnn_vals_mat[:,11], (batch_size, 5, 1)).float())[1].squeeze(0)\n",
        "\n",
        "        ll_n0 = F.relu(self.ll_s[0](rnn_vals_mat[:,0].float()))\n",
        "        ll_n1 = F.relu(self.ll_s[1](rnn_vals_mat[:,1].float()))\n",
        "        ll_n2 = F.relu(self.ll_s[2](rnn_vals_mat[:,2].float()))\n",
        "        ll_n3 = F.relu(self.ll_s[3](rnn_vals_mat[:,3].float()))\n",
        "        ll_n4 = F.relu(self.ll_s[4](rnn_vals_mat[:,4].float()))\n",
        "        ll_n5 = F.relu(self.ll_s[5](rnn_vals_mat[:,5].float()))\n",
        "        ll_n6 = F.relu(self.ll_s[6](rnn_vals_mat[:,6].float()))\n",
        "        ll_n7 = F.relu(self.ll_s[7](rnn_vals_mat[:,7].float()))\n",
        "        ll_n8 = F.relu(self.ll_s[8](rnn_vals_mat[:,8].float()))\n",
        "        ll_n9 = F.relu(self.ll_s[9](rnn_vals_mat[:,9].float()))\n",
        "        ll_n10 = F.relu(self.ll_s[10](rnn_vals_mat[:,10].float()))\n",
        "        ll_n11 = F.relu(self.ll_s[11](rnn_vals_mat[:,11].float()))\n",
        "\n",
        "        # orientation embedding\n",
        "        embed_output = self.orien_em(orient.int())\n",
        "        # send concatenate data to input hidden layer\n",
        "        # hidden_input = torch.cat((h_n0, h_n1, h_n2, h_n3, h_n4, h_n5, h_n6, h_n7, h_n8, h_n9, h_n10, h_n11, embed_output), dim=1)\n",
        "        hidden_input = torch.cat((ll_n0, ll_n1, ll_n2, ll_n3, ll_n4, ll_n5, ll_n6, ll_n7, ll_n8, ll_n9, ll_n10, ll_n11, embed_output), dim=1)\n",
        "        # hidden_input = F.dropout(hidden_input, p = 0.1)\n",
        "        hidden_output = F.relu(self.hidden_layer(hidden_input))\n",
        "        # hidden_output = F.dropout(hidden_output, p=0.2)\n",
        "        class_output = self.output_layer(hidden_output)\n",
        "        softmax_output = F.softmax(class_output, dim=1)\n",
        "        return softmax_output\n",
        "        "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TNbA7Rf76etq"
      },
      "source": [
        "Set up dataset and loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "I1hcC50V6gxv"
      },
      "outputs": [],
      "source": [
        "full_dataset = torch.tensor(pd.read_csv('data_set.csv', header=None).to_numpy())\n",
        "train_size = int(0.8 * len(full_dataset))\n",
        "test_size = len(full_dataset) - train_size\n",
        "train_data = torch.zeros((train_size, full_dataset.shape[1]))\n",
        "test_data = torch.zeros((train_size, full_dataset.shape[1]))\n",
        "\n",
        "# need to do split training dataset slices\n",
        "slice_size = (full_dataset.shape[0]/100)\n",
        "for i in range(100):\n",
        "    full_offset = int(i * slice_size)\n",
        "    train_offset = int(0.8 * i * slice_size)\n",
        "    test_offset = int(0.2 * i * slice_size)\n",
        "    train_data[train_offset:train_offset+8000] = full_dataset[full_offset:full_offset+8000]\n",
        "    test_data[test_offset:test_offset+2000] = full_dataset[full_offset+8000:full_offset+10000]\n",
        "\n",
        "batch_size = 100\n",
        "train_dataset = BLEDataset(train_data)\n",
        "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size, shuffle=True)\n",
        "test_dataset = BLEDataset(test_data)\n",
        "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GjHNyEom2q_K"
      },
      "source": [
        "Train your network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R_QDNqAx2tYi",
        "outputId": "a0877032-e29e-4bc7-b691-060234c2cc57"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0\n",
            "train accuracy: 0.35706 train loss: 244.7741823643446\n",
            "epoch: 1\n",
            "train accuracy: 0.70573 train loss: 156.3016298338771\n",
            "epoch: 2\n",
            "train accuracy: 0.80386 train loss: 109.39090877724811\n",
            "epoch: 3\n",
            "train accuracy: 0.85871125 train loss: 83.05453492701054\n",
            "epoch: 4\n",
            "train accuracy: 0.87768375 train loss: 68.07236839644611\n",
            "epoch: 5\n",
            "train accuracy: 0.8840725 train loss: 59.90869466739241\n",
            "epoch: 6\n",
            "train accuracy: 0.901885 train loss: 50.33133940771222\n",
            "epoch: 7\n",
            "train accuracy: 0.90502875 train loss: 46.24447065836284\n",
            "epoch: 8\n",
            "train accuracy: 0.906085 train loss: 44.08743194071576\n",
            "epoch: 9\n",
            "train accuracy: 0.906875 train loss: 42.67794895358384\n",
            "epoch: 10\n",
            "train accuracy: 0.90744375 train loss: 41.69471454073209\n",
            "epoch: 11\n",
            "train accuracy: 0.90779125 train loss: 40.98216472467175\n",
            "epoch: 12\n",
            "train accuracy: 0.90810625 train loss: 40.427024846489076\n",
            "epoch: 13\n",
            "train accuracy: 0.90836125 train loss: 39.9756665789173\n",
            "epoch: 14\n",
            "train accuracy: 0.90851875 train loss: 39.619331859459635\n",
            "epoch: 15\n",
            "train accuracy: 0.9086675 train loss: 39.32686732444563\n",
            "epoch: 16\n",
            "train accuracy: 0.90880375 train loss: 39.08197552344063\n",
            "epoch: 17\n",
            "train accuracy: 0.908895 train loss: 38.87039357959293\n",
            "epoch: 18\n",
            "train accuracy: 0.9089275 train loss: 38.6878937430447\n",
            "epoch: 19\n",
            "train accuracy: 0.90901375 train loss: 38.518012231448665\n",
            "epoch: 20\n",
            "train accuracy: 0.909075 train loss: 38.36737361451378\n",
            "epoch: 21\n",
            "train accuracy: 0.90913625 train loss: 38.23912322943215\n",
            "epoch: 22\n",
            "train accuracy: 0.90921625 train loss: 38.1058665139135\n",
            "epoch: 23\n",
            "train accuracy: 0.90924375 train loss: 37.98270963173127\n",
            "epoch: 24\n",
            "train accuracy: 0.90928125 train loss: 37.86854658841912\n",
            "epoch: 25\n",
            "train accuracy: 0.9093025 train loss: 37.75188279620488\n",
            "epoch: 26\n",
            "train accuracy: 0.9093525 train loss: 37.64579386764672\n",
            "epoch: 27\n",
            "train accuracy: 0.90934125 train loss: 37.53836589702405\n",
            "epoch: 28\n",
            "train accuracy: 0.90935625 train loss: 37.43869456237735\n",
            "epoch: 29\n",
            "train accuracy: 0.90938125 train loss: 37.351134001786704\n",
            "epoch: 30\n",
            "train accuracy: 0.909415 train loss: 37.266943458715104\n",
            "epoch: 31\n",
            "train accuracy: 0.9094225 train loss: 37.1912904100318\n",
            "epoch: 32\n",
            "train accuracy: 0.909435 train loss: 37.12220381665975\n",
            "epoch: 33\n",
            "train accuracy: 0.9094575 train loss: 37.05848715562024\n",
            "epoch: 34\n",
            "train accuracy: 0.9094725 train loss: 36.99105645091913\n",
            "epoch: 35\n",
            "train accuracy: 0.9094675 train loss: 36.895938599453075\n",
            "epoch: 36\n",
            "train accuracy: 0.9094925 train loss: 36.785194995376514\n",
            "epoch: 37\n",
            "train accuracy: 0.909495 train loss: 36.703161607147194\n",
            "epoch: 38\n",
            "train accuracy: 0.90955 train loss: 36.62887550632877\n",
            "epoch: 39\n",
            "train accuracy: 0.9095625 train loss: 36.56544016714906\n",
            "epoch: 40\n",
            "train accuracy: 0.90956375 train loss: 36.50302679838205\n",
            "epoch: 41\n",
            "train accuracy: 0.90957 train loss: 36.44730850348424\n",
            "epoch: 42\n",
            "train accuracy: 0.90958375 train loss: 36.386993249398074\n",
            "epoch: 43\n",
            "train accuracy: 0.90961 train loss: 36.32954575607437\n",
            "epoch: 44\n",
            "train accuracy: 0.90963875 train loss: 36.27058498491533\n",
            "epoch: 45\n",
            "train accuracy: 0.9096175 train loss: 36.21618066576775\n",
            "epoch: 46\n",
            "train accuracy: 0.90966 train loss: 36.1614879858098\n",
            "epoch: 47\n",
            "train accuracy: 0.90965375 train loss: 36.11243022745475\n",
            "epoch: 48\n",
            "train accuracy: 0.9096975 train loss: 36.06819650786929\n",
            "epoch: 49\n",
            "train accuracy: 0.90967375 train loss: 36.02838447304384\n"
          ]
        }
      ],
      "source": [
        "def accuracy(output, labels, num_correct, num_total):\n",
        "    # print(\"output shape:\", output.shape)\n",
        "    # print(\"labels shape:\", labels.shape)\n",
        "    _, predictions = torch.max(output, 1)\n",
        "    _, actuals = torch.max(labels, 1)\n",
        "    # print(\"predictions shape:\", predictions.shape)\n",
        "    # print(\"actuals shape:\", actuals.shape)\n",
        "    # compare predictions to true label\n",
        "    correct = np.squeeze(predictions.eq(actuals.view_as(predictions)))\n",
        "    # print(\"predict labels:\", predictions)\n",
        "    # print(\"actual labels:\", actuals)\n",
        "    # print(\"correct results:\", correct)\n",
        "    for i in range(len(actuals)):\n",
        "        num_correct += correct[i].item()\n",
        "        num_total += 1\n",
        "    return num_correct, num_total\n",
        "\n",
        "def train(model, data_loader, batch_size):  # try RNN next\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr = 0.0003)\n",
        "    criterion = nn.MSELoss()\n",
        "    epochs = 50\n",
        "    model = model.to(device)\n",
        "\n",
        "    def train_epoch():\n",
        "        num_correct = 0\n",
        "        num_total = 0\n",
        "        epoch_loss = 0\n",
        "        model.train()\n",
        "        for features, labels in data_loader:\n",
        "            # run model and get output \n",
        "            features = features.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = model(features)\n",
        "            # get accuracy \n",
        "            num_correct, num_total = accuracy(outputs, labels, num_correct, num_total)\n",
        "            # get residuals\n",
        "            loss = criterion(outputs, labels)\n",
        "            # clear out gradient\n",
        "            optimizer.zero_grad()\n",
        "            # back propagate with loss funciton\n",
        "            loss.backward()\n",
        "            # gradient step\n",
        "            optimizer.step()\n",
        "            epoch_loss += loss.item()\n",
        "        return num_correct/num_total, epoch_loss\n",
        "        pass\n",
        "\n",
        "    for e in range(epochs):\n",
        "        print(\"epoch:\", e)\n",
        "        train_accuracy, train_loss = train_epoch()\n",
        "        print(\"train accuracy:\", train_accuracy, \"train loss:\", train_loss)\n",
        "\n",
        "model = LOC_NN()\n",
        "train(model, train_dataloader, batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BnQpxGJE2sOU"
      },
      "source": [
        "Test your network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I8PorDUN2t_W",
        "outputId": "8137059f-17d3-48f1-8caf-66f5b6180736"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test accuracy: 0.22742625 test loss: 41775.97622126341\n"
          ]
        }
      ],
      "source": [
        "def evaluate(model):\n",
        "    model.eval()\n",
        "\n",
        "def test(model, test_loader):\n",
        "    num_correct = 0\n",
        "    num_total = 0\n",
        "    test_loss = 0.0\n",
        "    criterion = nn.MSELoss()\n",
        "    evaluate(model)\n",
        "    for features, labels in test_loader:\n",
        "        features = features.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(features)\n",
        "        # get accuracy \n",
        "        num_correct, num_total = accuracy(outputs, labels, num_correct, num_total)\n",
        "        # add loss\n",
        "        loss = criterion(outputs, labels.long())\n",
        "        test_loss += loss.item() * features.size(0)\n",
        "    return num_correct/num_total, test_loss\n",
        "\n",
        "test_accuracy, test_loss = test(model, test_dataloader)\n",
        "print(\"test accuracy:\", test_accuracy, \"test loss:\", test_loss)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}